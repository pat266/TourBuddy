{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "uZR3iGJJtdDE",
      "metadata": {
        "id": "uZR3iGJJtdDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e970fa09-6942-4e01-b453-6b3d24e5b651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain==0.0.333 openai==1.2.2\n",
        "!pip -q install duckduckgo-search\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wPdWz1IdxyBR",
      "metadata": {
        "id": "wPdWz1IdxyBR"
      },
      "source": [
        "Setting up some keys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k_oRniCLjpN",
        "outputId": "96b452d1-d396-4aca-e3a4-3bc822edc7da"
      },
      "id": "0k_oRniCLjpN",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.333\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, anyio, async-timeout, dataclasses-json, jsonpatch, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1571b632",
      "metadata": {
        "id": "1571b632"
      },
      "source": [
        "\n",
        "# Custom Tools & Agents 🤖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c02c4fa2",
      "metadata": {
        "id": "c02c4fa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2dc6eba-e942-435e-dd2a-a8f079cabb32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key retrieved successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv('.env')\n",
        "\n",
        "# Retrieve the API key\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "if openai_api_key is not None and len(openai_api_key) != 0:\n",
        "    print(\"API key retrieved successfully.\")\n",
        "else:\n",
        "    print(\"API key not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "73bfcbb6",
      "metadata": {
        "id": "73bfcbb6"
      },
      "outputs": [],
      "source": [
        "# from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the turbo LLM\n",
        "turbo_llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-1106\") # 16k tokens sent, 4k tokens received"
      ],
      "metadata": {
        "id": "Lald4gCltB4V"
      },
      "id": "Lald4gCltB4V",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard Tool"
      ],
      "metadata": {
        "id": "7DKXFGHhxNcK"
      },
      "id": "7DKXFGHhxNcK"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun, BaseTool\n",
        "from langchain.agents import initialize_agent, AgentType, Tool, AgentExecutor\n",
        "from langchain.document_loaders import RecursiveUrlLoader\n",
        "from langchain.chains import LLMMathChain\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import re\n",
        "import requests\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "llm_math_chain = LLMMathChain.from_llm(llm=turbo_llm, verbose=True)"
      ],
      "metadata": {
        "id": "kOVncXZtxT_0"
      },
      "id": "kOVncXZtxT_0",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class WebPageTool(BaseTool):\n",
        "#     name = \"Get Webpage\"\n",
        "#     description = \"Useful for when you need to get the content from a specific webpage\"\n",
        "\n",
        "#     def _run(self, webpage: str):\n",
        "#         response = requests.get(webpage)\n",
        "#         html_content = response.text\n",
        "\n",
        "#         def strip_html_tags(html_content):\n",
        "#             soup = bs(html_content, \"html.parser\")\n",
        "#             stripped_text = soup.get_text()\n",
        "#             return stripped_text\n",
        "\n",
        "#         stripped_content = strip_html_tags(html_content)\n",
        "#         if len(stripped_content) > 4000:\n",
        "#             stripped_content = stripped_content[:4000]\n",
        "#         return stripped_content\n",
        "\n",
        "#     def _arun(self, webpage: str):\n",
        "#         raise NotImplementedError(\"This tool does not support async\")\n",
        "\n",
        "# page_getter = WebPageTool()\n",
        "\n",
        "def extract_text_and_limit_tokens(html, token_limit=4097):\n",
        "    # Extract text with BeautifulSoup\n",
        "    text = bs(html, \"html.parser\").text\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "    # Approximate tokenization by splitting on spaces\n",
        "    tokens = text.split(' ')\n",
        "\n",
        "    # Limit the number of tokens and join back into a string\n",
        "    limited_text = ' '.join(tokens[:token_limit])\n",
        "    return limited_text\n",
        "\n",
        "def crawl_site(url):\n",
        "    loader = RecursiveUrlLoader(\n",
        "        url=url,\n",
        "        max_depth=2,\n",
        "        extractor=lambda x: extract_text_and_limit_tokens(x, 6000)\n",
        "    )\n",
        "    docs = loader.load()\n",
        "    return docs"
      ],
      "metadata": {
        "id": "ZEKFn9UDEmMS"
      },
      "id": "ZEKFn9UDEmMS",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name = \"search\",\n",
        "        func=search.run,\n",
        "        description=\"Search the internet to find helpful websites.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=llm_math_chain.run,\n",
        "        description=\"Useful for when you need to answer questions about math\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"site_crawler\",\n",
        "        func=crawl_site,\n",
        "        description=\"Crawl a website up to depth 2.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "mrkl = initialize_agent(\n",
        "    agent=AgentType.OPENAI_FUNCTIONS,\n",
        "    tools=tools,\n",
        "    llm=turbo_llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method='generate',\n",
        ")"
      ],
      "metadata": {
        "id": "9h7l5_UrE6b-"
      },
      "id": "9h7l5_UrE6b-",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_prompt = '''You are a helpful AI assistant.''' # can change this later\n",
        "mrkl.agent.prompt.messages[0].content = fixed_prompt\n",
        "mrkl.agent.prompt.messages[0].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4Umihm5HPA5l",
        "outputId": "83963615-e178-4025-d928-8c40510371e9"
      },
      "id": "4Umihm5HPA5l",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are a helpful AI assistant.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "location = \"Maple Street Guitars\"\n",
        "# result = mrkl.run(f\"Search the internet about {location} and crawl at most 5 websites to find the necessary information about the price and what people usually do or order in there.\")"
      ],
      "metadata": {
        "id": "q6VHBocdq6BK"
      },
      "id": "q6VHBocdq6BK",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(result)"
      ],
      "metadata": {
        "id": "Huj1p9wLQujn"
      },
      "id": "Huj1p9wLQujn",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result"
      ],
      "metadata": {
        "id": "8JbZFVWx0pmG"
      },
      "id": "8JbZFVWx0pmG",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Searching maps"
      ],
      "metadata": {
        "id": "xZ1z5VckY637"
      },
      "id": "xZ1z5VckY637"
    },
    {
      "cell_type": "code",
      "source": [
        "from duckduckgo_search import DDGS\n",
        "\n",
        "ddgs = DDGS()\n",
        "\n",
        "# result = list(ddgs.maps('good restaurants around Atlanta, GA', max_results=50))"
      ],
      "metadata": {
        "id": "tGsKPLaSUuXq"
      },
      "id": "tGsKPLaSUuXq",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List of recommended places"
      ],
      "metadata": {
        "id": "dNfBEvdBd8GS"
      },
      "id": "dNfBEvdBd8GS"
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "from openai import OpenAI\n",
        "\n",
        "def get_recommended_places(latitude=\"33.771030\", longitude= \"-84.391090\", radius=10): # defaults on north ave apartment\n",
        "    # List of keys to keep\n",
        "    keys_to_keep = ['title', 'address', 'latitude', 'longitude', 'phone', 'preference']\n",
        "    # List of user preferences\n",
        "    preferences_list = ['sports', 'art and culture', 'museum and history', 'food and dining', 'nature and outdoors', 'music', 'technology', 'shopping', 'movies and entertainment']\n",
        "    # List of recommended places based on the user preferences\n",
        "    recommended_places_list = []\n",
        "    for preference in preferences_list:\n",
        "        for original_dict in ddgs.maps(f\"places related to {preference}\", latitude=str(latitude), longitude= str(longitude), radius=radius, max_results=10):\n",
        "            # Add the 'preference' key and value directly to the original dictionary\n",
        "            original_dict['preference'] = preference\n",
        "            recommended_places_list.append({k: original_dict[k] for k in keys_to_keep if k in original_dict})\n",
        "    return recommended_places_list\n",
        "\n",
        "def generate_information(place_name, client):\n",
        "    prompt = f\"\"\"\n",
        "    Based on what you know, generate about this place: {place_name}.\n",
        "    Key information such as the environment and atmosphere of the place. If possible, estimate the range of the cost, and give some recommendations of what food people ordered or activities they did.\n",
        "    Label them appropriately, and go to the next line for each detail.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-1106\",\n",
        "        max_tokens=200,\n",
        "        temperature=0,\n",
        "        messages=\n",
        "        [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful assistant.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            },\n",
        "        ],\n",
        "\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def thread_worker(place, client):\n",
        "    try:\n",
        "        place['generated_info'] = generate_information(place['title'], client)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating information for {place['title']}: {e}\")\n",
        "\n",
        "# generate information using threading\n",
        "def process_places_concurrently(places, client):\n",
        "    threads = []\n",
        "    for place in places:\n",
        "        t = threading.Thread(target=thread_worker, args=(place, client))\n",
        "        threads.append(t)\n",
        "        t.start()\n",
        "\n",
        "    # Wait for all threads to complete\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "\n",
        "    return places"
      ],
      "metadata": {
        "id": "q45MdjUwtGv5"
      },
      "id": "q45MdjUwtGv5",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "recommended_places_list = get_recommended_places(latitude=\"33.771030\", longitude= \"-84.391090\", radius=10)\n",
        "updated_recommended_places_list = process_places_concurrently(recommended_places_list, client)\n",
        "updated_recommended_places_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCA75hTJhGqP",
        "outputId": "77ec119a-b9ef-435e-db0a-dee67363e052"
      },
      "id": "yCA75hTJhGqP",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'Rodney Cook Sr. Park',\n",
              "  'address': '609 Thurmond St NW, Atlanta, GA  30314, United States',\n",
              "  'latitude': 33.7617605739047,\n",
              "  'longitude': -84.4076693058014,\n",
              "  'phone': '+14048810900',\n",
              "  'preference': 'sports',\n",
              "  'generated_info': \"Rodney Cook Sr. Park is a beautiful urban park located in the historic Vine City neighborhood of Atlanta, Georgia. The park offers a peaceful and serene environment with lush green spaces, walking trails, and a stunning water feature.\\n\\nAtmosphere: The atmosphere at Rodney Cook Sr. Park is relaxed and inviting, making it a perfect place for a leisurely stroll, a picnic, or simply enjoying the natural surroundings.\\n\\nCost: The park is free to enter and enjoy, making it an affordable option for a day out in Atlanta.\\n\\nFood: Visitors to Rodney Cook Sr. Park often bring their own picnic lunches to enjoy in the park's designated picnic areas. Nearby restaurants and food trucks also offer a variety of delicious options for those looking to grab a bite to eat before or after their visit.\\n\\nActivities: Popular activities at Rodney Cook Sr. Park include walking or jogging along the trails, taking in the beautiful views of the water feature, and simply relaxing in the peaceful outdoor setting. The park also hosts community\"},\n",
              " {'title': 'R. Thomas Deluxe Grill',\n",
              "  'address': '1812 Peachtree St NW, Atlanta, GA 30309-1858',\n",
              "  'latitude': 33.8042602,\n",
              "  'longitude': -84.3937309,\n",
              "  'phone': '+14048722942',\n",
              "  'preference': 'food and dining',\n",
              "  'generated_info': 'R. Thomas Deluxe Grill is a popular restaurant located in Atlanta, Georgia. The environment and atmosphere of the place is casual and relaxed, with a unique outdoor dining area featuring a tropical garden and waterfall.\\n\\nCost range: The cost range at R. Thomas Deluxe Grill is moderate, with most entrees falling in the range of $10 to $20.\\n\\nFood recommendations: Customers often enjoy the grilled salmon, veggie burgers, and the extensive selection of smoothies and fresh juices.\\n\\nActivities: Visitors often enjoy sitting in the outdoor garden area, which provides a peaceful and serene dining experience. The restaurant also offers a pet-friendly environment, so many people bring their furry friends along to enjoy the atmosphere.'},\n",
              " {'title': 'Caribbean Delight',\n",
              "  'address': '576 Lee St SW, #b, Atlanta, GA 30310',\n",
              "  'latitude': 33.7392397,\n",
              "  'longitude': -84.4138299,\n",
              "  'phone': '+14047526173',\n",
              "  'preference': 'food and dining',\n",
              "  'generated_info': 'Caribbean Delight is a vibrant and lively restaurant that captures the essence of the Caribbean. The atmosphere is relaxed and welcoming, with colorful decor and a tropical ambiance.\\n\\nCost range: The cost range at Caribbean Delight is moderate, making it an affordable option for those looking to enjoy Caribbean cuisine.\\n\\nFood recommendations: Customers often order popular dishes such as jerk chicken, coconut shrimp, plantains, and rice and peas. The restaurant also offers a variety of tropical cocktails and refreshing beverages.\\n\\nActivities: Guests can enjoy live music and entertainment, adding to the festive atmosphere. Additionally, Caribbean Delight occasionally hosts themed events and special celebrations, providing a fun and engaging experience for visitors.'},\n",
              " {'title': 'Tech Square',\n",
              "  'address': '79 5th St NW, Atlanta, GA  30308, United States',\n",
              "  'latitude': 33.777007,\n",
              "  'longitude': -84.389108,\n",
              "  'phone': '+14043306000',\n",
              "  'preference': 'technology',\n",
              "  'generated_info': 'Tech Square is a vibrant and bustling area located in the heart of Atlanta, Georgia. The environment is dynamic and innovative, with a mix of tech companies, startups, and academic institutions creating a lively and forward-thinking atmosphere.\\n\\nCost range: The cost range for dining and activities in Tech Square can vary, with options to suit different budgets. There are affordable eateries as well as higher-end restaurants, and activities can range from free events to paid experiences.\\n\\nFood recommendations: Visitors to Tech Square often enjoy a diverse range of cuisines, including popular options such as Korean BBQ, sushi, and gourmet burgers. Local favorites include the innovative fusion dishes at food halls and the artisanal coffee and pastries at trendy cafes.\\n\\nActivity recommendations: Tech Square offers a range of activities, from attending tech meetups and networking events to exploring the latest innovations at tech showcases. Visitors can also enjoy outdoor events in the square, such as live music performances and food festivals. Additionally, the area is known for its proximity to cultural'},\n",
              " {'title': 'Peachtree Battle Shopping Center',\n",
              "  'address': '2325 Peachtree Rd NE, Atlanta, GA  30309, United States',\n",
              "  'latitude': 33.8195632497893,\n",
              "  'longitude': -84.3866664357483,\n",
              "  'phone': '+18888572929',\n",
              "  'preference': 'shopping',\n",
              "  'generated_info': 'Peachtree Battle Shopping Center is a bustling retail destination located in the heart of Atlanta, Georgia. The atmosphere is vibrant and welcoming, with a mix of upscale and casual shops and restaurants.\\n\\nCost Range: The cost range for dining and shopping at Peachtree Battle Shopping Center varies, with options to suit different budgets.\\n\\nFood Recommendations: Visitors often enjoy dining at popular eateries such as La Fonda Latina for delicious Latin cuisine, or Flying Biscuit Cafe for a hearty Southern breakfast.\\n\\nActivities: Shopping for trendy fashion at boutiques, grabbing a coffee and strolling around the outdoor plaza, and enjoying a leisurely meal with friends or family are popular activities at Peachtree Battle Shopping Center.'},\n",
              " {'title': 'Flats at Ponce City Market',\n",
              "  'address': '650 North Ave NE, Unit 187, Atlanta, GA  30308, United States',\n",
              "  'latitude': 33.771564,\n",
              "  'longitude': -84.3673637,\n",
              "  'phone': '+14044104400',\n",
              "  'preference': 'shopping',\n",
              "  'generated_info': \"The Flats at Ponce City Market is a modern residential community located in the heart of Atlanta, Georgia. It offers a vibrant and urban environment with a mix of historic charm and contemporary amenities. The atmosphere is lively and bustling, with a strong sense of community and a diverse range of activities and events.\\n\\nCost Range: The cost of living at the Flats at Ponce City Market varies depending on the size and type of apartment, but it generally falls within the mid to high range for Atlanta's housing market.\\n\\nFood Recommendations: Residents often enjoy dining at the various restaurants and eateries located within Ponce City Market, such as H&F Burger, Botiwalla, and Minero. These establishments offer a wide range of delicious options, from gourmet burgers to Indian street food and Mexican cuisine.\\n\\nActivities: Residents can take advantage of the numerous amenities and activities available within the community, including rooftop yoga classes, social events at the community lounge, and access to the BeltLine for walking, running\"},\n",
              " {'title': 'AMC Phipps Plaza 14',\n",
              "  'address': '3500 Peachtree Rd NE, Atlanta, GA 30326-1222',\n",
              "  'latitude': 33.8526399198563,\n",
              "  'longitude': -84.3628527199348,\n",
              "  'phone': '+14042311492',\n",
              "  'preference': 'movies and entertainment',\n",
              "  'generated_info': \"AMC Phipps Plaza 14 is a modern and upscale movie theater located in the heart of Atlanta, Georgia. The environment is luxurious and comfortable, with spacious seating and state-of-the-art technology, providing a premium movie-watching experience.\\n\\nCost Range: The cost of tickets at AMC Phipps Plaza 14 typically ranges from $12 to $20, depending on the time of day and the type of movie being shown.\\n\\nFood Recommendations: Moviegoers often enjoy classic theater snacks such as popcorn, candy, and soda. Additionally, the theater offers a variety of gourmet options including hot dogs, nachos, and specialty popcorn flavors.\\n\\nActivities: In addition to watching movies, visitors can also take advantage of the theater's special events, such as screenings of classic films, live broadcasts of theater performances, and special movie marathons. The theater also hosts private events and screenings for groups and parties.\"},\n",
              " {'title': 'Midtown Art Cinema',\n",
              "  'address': '931 Monroe Dr NE, Atlanta, GA 30308-1793',\n",
              "  'latitude': 33.7789868,\n",
              "  'longitude': -84.3668246,\n",
              "  'phone': '+14048790160',\n",
              "  'preference': 'movies and entertainment',\n",
              "  'generated_info': \"Midtown Art Cinema is a popular independent movie theater located in the heart of Atlanta, Georgia. The atmosphere of the place is artsy and eclectic, with a focus on showcasing independent and foreign films. The environment is cozy and intimate, providing a unique and immersive movie-watching experience.\\n\\nCost range: The ticket prices at Midtown Art Cinema typically range from $10 to $15, making it an affordable option for moviegoers looking for a more diverse selection of films.\\n\\nFood recommendations: Visitors often enjoy grabbing a bite to eat at the theater's café, which offers a variety of gourmet snacks and light meals. Popular choices include artisanal popcorn, charcuterie boards, and craft beer or wine.\\n\\nActivities: In addition to watching films, patrons can also participate in special events such as film festivals, director Q&A sessions, and themed movie nights, adding to the overall cultural experience of the venue.\"},\n",
              " {'title': 'IPIC Atlanta',\n",
              "  'address': '1197 Peachtree St NE, Suite350, Atlanta, GA 30361-3502',\n",
              "  'latitude': 33.7873215,\n",
              "  'longitude': -84.3820624,\n",
              "  'phone': '+14708938525',\n",
              "  'preference': 'movies and entertainment',\n",
              "  'generated_info': 'IPIC Atlanta is a luxury movie theater located in the Buckhead neighborhood of Atlanta, Georgia. The atmosphere is upscale and sophisticated, with a focus on providing a high-end cinematic experience.\\n\\nCost range: The cost of tickets at IPIC Atlanta typically ranges from $20 to $30, depending on the time of day and the type of seating chosen.\\n\\nFood recommendations: Guests at IPIC Atlanta can enjoy a full dining experience while watching a movie. Popular food items include gourmet burgers, truffle fries, sushi, and artisanal pizzas.\\n\\nActivities: In addition to watching movies, guests can also enjoy a selection of cocktails and other beverages at the bar, making it a great place for a night out with friends or a special date.'},\n",
              " {'title': 'Regal Cinemas',\n",
              "  'address': '261 19th St NW, Unit 1250, Atlanta, GA 30363, United States',\n",
              "  'latitude': 33.7938329,\n",
              "  'longitude': -84.3963199,\n",
              "  'phone': '+18444627342',\n",
              "  'preference': 'movies and entertainment',\n",
              "  'generated_info': 'Regal Cinemas is a popular movie theater chain known for its comfortable seating and state-of-the-art sound and visual technology. The environment is typically lively and bustling, especially during peak movie times, creating an exciting atmosphere for moviegoers.\\n\\nCost range: The cost of tickets at Regal Cinemas can vary depending on the location and time of day, but generally falls within the mid-range compared to other movie theaters.\\n\\nFood recommendations: Popcorn, nachos, and candy are popular choices at Regal Cinemas. Many patrons also enjoy pairing their movie experience with a variety of fountain drinks and specialty beverages.\\n\\nActivities: In addition to watching movies, Regal Cinemas often hosts special events such as advance screenings, film festivals, and themed movie nights, providing additional entertainment options for visitors.'},\n",
              " {'title': 'NCG Cinemas',\n",
              "  'address': '3365 Buford Hwy NE, Unit 920, Atlanta, GA 30329, United States',\n",
              "  'latitude': 33.843441,\n",
              "  'longitude': -84.3250988,\n",
              "  'phone': '+14703750333',\n",
              "  'preference': 'movies and entertainment',\n",
              "  'generated_info': 'NCG Cinemas is a popular movie theater chain known for its comfortable and modern facilities. The atmosphere is typically lively and welcoming, with a focus on providing a great movie-watching experience for all visitors.\\n\\nCost range: The cost of tickets at NCG Cinemas can vary depending on the location and time of day, but generally falls within the mid-range compared to other theaters.\\n\\nFood recommendations: Visitors often enjoy classic movie snacks such as popcorn, candy, and soda while watching their favorite films. Additionally, NCG Cinemas may offer a variety of hot food options, including pizza, nachos, and hot dogs.\\n\\nActivities: In addition to watching movies, NCG Cinemas may host special events such as movie marathons, advance screenings, and special promotions for families and groups. Some locations may also offer arcade games or other entertainment options for guests to enjoy before or after their movie.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating information concurrently"
      ],
      "metadata": {
        "id": "aIuJCxUWjVyZ"
      },
      "id": "aIuJCxUWjVyZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Websites result from place"
      ],
      "metadata": {
        "id": "TaOp0ZA_dkAV"
      },
      "id": "TaOp0ZA_dkAV"
    },
    {
      "cell_type": "code",
      "source": [
        "detailed_result_list = []\n",
        "for r in ddgs.text('R. Thomas Deluxe Grill', max_results=10):\n",
        "    detailed_result_list.append(r)\n",
        "detailed_result_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZWoi7yfeYc-",
        "outputId": "9f4dc82d-6d17-4b58-bc40-ae7b96097d0a"
      },
      "id": "tZWoi7yfeYc-",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'R. Thomas Deluxe Grill',\n",
              "  'href': 'https://www.rthomasdeluxegrill.net/',\n",
              "  'body': 'R. Thomas Deluxe Grill R. Thomas Deluxe Grill in Atlanta, GA. Food for everyone! We use fresh vegetables, fruit and meat across our menu. We have something yummy for every type of tummy. From burgers to vegan we aim to feed you. Write a Review, Win $500! Help guests by leaving a review of your favorite dishes.'},\n",
              " {'title': 'R. THOMAS DELUXE GRILL - 1009 Photos & 1167 Reviews - Yelp',\n",
              "  'href': 'https://www.yelp.com/biz/r-thomas-deluxe-grill-atlanta',\n",
              "  'body': 'R. Thomas Deluxe Grill 3.9 (1,167 reviews) Claimed $$ Vegetarian, Vegan, Breakfast & Brunch Open 7:00 AM - 11:00 PM See hours Verified by the business 2 months ago See all 1.0k photos Write a review Add photo Menu Popular dishes View full menu French Toast 43 Photos 168 Reviews Thai Express 14 Photos 56 Reviews Spicy Fish Tacos 19 Photos 49 Reviews'},\n",
              " {'title': 'R. Thomas Deluxe Grill - American Restaurant in Atlanta',\n",
              "  'href': 'https://rthomasdeluxegrill.business.site/',\n",
              "  'body': 'R. Thomas Deluxe Grill. American Restaurant in Atlanta. Open until 5:00 AM tomorrow. View Menu Call (404) 881-0246 Get directions Get Quote WhatsApp (404) 881-0246 Message (404) 881-0246 Contact Us Find Table Make Appointment Place Order. Testimonials.'},\n",
              " {'title': 'R. Thomas Deluxe Grill | Atlanta GA - Facebook',\n",
              "  'href': 'https://www.facebook.com/rthomasdeluxegrill/',\n",
              "  'body': 'R. Thomas Deluxe Grill, Atlanta, Georgia. 13,926 likes · 195 talking about this · 28,081 were here. est. 1985, Atlanta restaurant offering wholesome food...'},\n",
              " {'title': 'R. THOMAS DELUXE GRILL, Atlanta - Buckhead - Tripadvisor',\n",
              "  'href': 'https://www.tripadvisor.com/Restaurant_Review-g60898-d435430-Reviews-R_Thomas_Deluxe_Grill-Atlanta_Georgia.html',\n",
              "  'body': 'R. Thomas Deluxe Grill Claimed Review Save Share 290 reviews #112 of 1,921 Restaurants in Atlanta $$ - $$$ American Vegetarian Friendly Vegan Options 1812 Peachtree St NW, Atlanta, GA 30309-1858 +1 404-872-2942 Website Closed now : See all hours Improve this listing See all (150) Ratings and reviews 4.5 290 reviews #112 RATINGS Food Service Value'},\n",
              " {'title': 'R. THOMAS DELUXE GRILL - 999 Photos & 1154 Reviews - Yelp',\n",
              "  'href': 'https://www.yelp.com/biz/r-thomas-deluxe-grill-atlanta?start=200',\n",
              "  'body': 'R. Thomas Deluxe Grill 1154 reviews Claimed $$ Vegan, American (Traditional), Breakfast & Brunch Open 7:00 AM - 11:00 PM Hours updated over 3 months ago See hours See all 1011 photos Menu French Toast 43 Photos 166 Reviews Thai Express 14 Photos 56 Reviews Spicy Fish Tacos 18 Photos 48 Reviews Veggie Sausage 10 Photos 30 Reviews'},\n",
              " {'title': 'R Thomas Deluxe Grill Delivery Menu - DoorDash',\n",
              "  'href': 'https://www.doordash.com/store/r-thomas-deluxe-grill-atlanta-21361',\n",
              "  'body': 'Prices on this menu are set directly by the Merchant. Prices may differ between Delivery and Pickup. Get delivery or takeout from R Thomas Deluxe Grill at 1812 Peachtree Street Northwest in Atlanta. Order online and track your order live. No delivery fee on your first order!'},\n",
              " {'title': 'R. THOMAS DELUXE GRILL - 1000 Photos & 1156 Reviews - Yelp',\n",
              "  'href': 'https://www.yelp.com/biz/r-thomas-deluxe-grill-atlanta?start=60',\n",
              "  'body': \"If it's unique surroundings you're after though, R. Thomas Deluxe grill has that definitely going for itself! See all photos from Jamarcus T. for R. Thomas Deluxe Grill. Useful 19. Funny 17. Cool 16. Brittany S. Elite 2023. Charlotte, NC. 36. 149. 267. 2/18/2020. 1 photo. What a tasty, late night spot! Came here for late dinner around midnight ...\"},\n",
              " {'title': 'R. Thomas Deluxe Grill - Uber Eats',\n",
              "  'href': 'https://www.ubereats.com/store/r-thomas-deluxe-grill/iHnj4R99RR2zTeH3GFS6-w',\n",
              "  'body': 'R. Thomas Deluxe Grill. 4.6 (99 ratings) • Burgers. • More info. 1812 Peachtree St Nw, Atlanta, GA 30309-1858. Enter your address above to see fees, and delivery + pickup estimates.'},\n",
              " {'title': 'R. Thomas Deluxe Grill',\n",
              "  'href': 'https://www.rthomasdeluxegrill.net/menus/in-house-menu',\n",
              "  'body': 'Opens in a new window Opens an external site Opens an external site in a new window Opens an external site Opens an external site in a new window'}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detailed_result_list[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYfo9gBROAKg",
        "outputId": "cf110d6c-f8cc-4379-da24-9a74b65ed23a"
      },
      "id": "eYfo9gBROAKg",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'R. Thomas Deluxe Grill',\n",
              " 'href': 'https://www.rthomasdeluxegrill.net/',\n",
              " 'body': 'R. Thomas Deluxe Grill R. Thomas Deluxe Grill in Atlanta, GA. Food for everyone! We use fresh vegetables, fruit and meat across our menu. We have something yummy for every type of tummy. From burgers to vegan we aim to feed you. Write a Review, Win $500! Help guests by leaving a review of your favorite dishes.'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crawl_site('https://www.rthomasdeluxegrill.net/') # not using because it does not crawl efficiently"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-RbQqZ2OalO",
        "outputId": "ca65139f-5684-43bf-fad3-2575330283eb"
      },
      "id": "m-RbQqZ2OalO",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Just a moment...Enable JavaScript and cookies to continue', metadata={'source': 'https://www.rthomasdeluxegrill.net/', 'title': 'Just a moment...', 'language': 'en-US'})]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4==4.11.2 Flask==3.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWomXTSwSJ_h",
        "outputId": "5ed49ec9-e97b-4dd0-bc5e-95bcd159ece9"
      },
      "id": "OWomXTSwSJ_h",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4==4.11.2 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Collecting Flask==3.0.0\n",
            "  Downloading flask-3.0.0-py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.11.2) (2.5)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask==3.0.0) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==3.0.0) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask==3.0.0) (2.1.2)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask==3.0.0) (8.1.7)\n",
            "Collecting blinker>=1.6.2 (from Flask==3.0.0)\n",
            "  Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask==3.0.0) (2.1.3)\n",
            "Installing collected packages: blinker, Flask\n",
            "  Attempting uninstall: blinker\n",
            "    Found existing installation: blinker 1.4\n",
            "\u001b[31mERROR: Cannot uninstall 'blinker'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crochet==2.1.1\n",
        "!pip install Scrapy==2.11.0\n",
        "!pip install readability-lxml==0.8.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4d52oVGS2CB",
        "outputId": "6b81dfea-1fc2-4654-999f-8ab7a9bb6571"
      },
      "id": "O4d52oVGS2CB",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crochet==2.1.1\n",
            "  Downloading crochet-2.1.1-py3-none-any.whl (31 kB)\n",
            "Collecting Twisted>=16.0 (from crochet==2.1.1)\n",
            "  Downloading twisted-23.10.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from crochet==2.1.1) (1.14.1)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from Twisted>=16.0->crochet==2.1.1) (23.1.0)\n",
            "Collecting automat>=0.8.0 (from Twisted>=16.0->crochet==2.1.1)\n",
            "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting constantly>=15.1 (from Twisted>=16.0->crochet==2.1.1)\n",
            "  Downloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
            "Collecting hyperlink>=17.1.1 (from Twisted>=16.0->crochet==2.1.1)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting incremental>=22.10.0 (from Twisted>=16.0->crochet==2.1.1)\n",
            "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from Twisted>=16.0->crochet==2.1.1) (4.5.0)\n",
            "Collecting zope-interface>=5 (from Twisted>=16.0->crochet==2.1.1)\n",
            "  Downloading zope.interface-6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.1/247.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from automat>=0.8.0->Twisted>=16.0->crochet==2.1.1) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.10/dist-packages (from hyperlink>=17.1.1->Twisted>=16.0->crochet==2.1.1) (3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope-interface>=5->Twisted>=16.0->crochet==2.1.1) (67.7.2)\n",
            "Installing collected packages: incremental, zope-interface, hyperlink, constantly, automat, Twisted, crochet\n",
            "Successfully installed Twisted-23.10.0 automat-22.10.0 constantly-23.10.4 crochet-2.1.1 hyperlink-21.0.0 incremental-22.10.0 zope-interface-6.1\n",
            "Collecting Scrapy==2.11.0\n",
            "  Downloading Scrapy-2.11.0-py2.py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.4/286.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Twisted<23.8.0,>=18.9.0 (from Scrapy==2.11.0)\n",
            "  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from Scrapy==2.11.0) (41.0.5)\n",
            "Collecting cssselect>=0.9.1 (from Scrapy==2.11.0)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting itemloaders>=1.0.1 (from Scrapy==2.11.0)\n",
            "  Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting parsel>=1.5.0 (from Scrapy==2.11.0)\n",
            "  Downloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from Scrapy==2.11.0) (23.3.0)\n",
            "Collecting queuelib>=1.4.2 (from Scrapy==2.11.0)\n",
            "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting service-identity>=18.1.0 (from Scrapy==2.11.0)\n",
            "  Downloading service_identity-23.1.0-py3-none-any.whl (12 kB)\n",
            "Collecting w3lib>=1.17.0 (from Scrapy==2.11.0)\n",
            "  Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from Scrapy==2.11.0) (6.1)\n",
            "Collecting protego>=0.1.15 (from Scrapy==2.11.0)\n",
            "  Downloading Protego-0.3.0-py2.py3-none-any.whl (8.5 kB)\n",
            "Collecting itemadapter>=0.1.0 (from Scrapy==2.11.0)\n",
            "  Downloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from Scrapy==2.11.0) (67.7.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from Scrapy==2.11.0) (23.2)\n",
            "Collecting tldextract (from Scrapy==2.11.0)\n",
            "  Downloading tldextract-5.1.0-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from Scrapy==2.11.0) (4.9.3)\n",
            "Collecting PyDispatcher>=2.0.5 (from Scrapy==2.11.0)\n",
            "  Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->Scrapy==2.11.0) (1.16.0)\n",
            "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->Scrapy==2.11.0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->Scrapy==2.11.0) (23.1.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->Scrapy==2.11.0) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->Scrapy==2.11.0) (0.3.0)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.10/dist-packages (from Twisted<23.8.0,>=18.9.0->Scrapy==2.11.0) (23.10.4)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from Twisted<23.8.0,>=18.9.0->Scrapy==2.11.0) (22.10.0)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from Twisted<23.8.0,>=18.9.0->Scrapy==2.11.0) (22.10.0)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.10/dist-packages (from Twisted<23.8.0,>=18.9.0->Scrapy==2.11.0) (21.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from Twisted<23.8.0,>=18.9.0->Scrapy==2.11.0) (4.5.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract->Scrapy==2.11.0) (3.4)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract->Scrapy==2.11.0) (2.31.0)\n",
            "Collecting requests-file>=1.4 (from tldextract->Scrapy==2.11.0)\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->Scrapy==2.11.0) (3.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Automat>=0.8.0->Twisted<23.8.0,>=18.9.0->Scrapy==2.11.0) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->Scrapy==2.11.0) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->Scrapy==2.11.0) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->Scrapy==2.11.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->Scrapy==2.11.0) (2023.7.22)\n",
            "Installing collected packages: PyDispatcher, w3lib, queuelib, protego, jmespath, itemadapter, cssselect, Twisted, requests-file, parsel, tldextract, service-identity, itemloaders, Scrapy\n",
            "  Attempting uninstall: Twisted\n",
            "    Found existing installation: Twisted 23.10.0\n",
            "    Uninstalling Twisted-23.10.0:\n",
            "      Successfully uninstalled Twisted-23.10.0\n",
            "Successfully installed PyDispatcher-2.0.7 Scrapy-2.11.0 Twisted-22.10.0 cssselect-1.2.0 itemadapter-0.8.0 itemloaders-1.1.0 jmespath-1.0.1 parsel-1.8.1 protego-0.3.0 queuelib-1.6.2 requests-file-1.5.1 service-identity-23.1.0 tldextract-5.1.0 w3lib-2.1.2\n",
            "Collecting readability-lxml==0.8.1\n",
            "  Downloading readability_lxml-0.8.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from readability-lxml==0.8.1) (5.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from readability-lxml==0.8.1) (4.9.3)\n",
            "Requirement already satisfied: cssselect in /usr/local/lib/python3.10/dist-packages (from readability-lxml==0.8.1) (1.2.0)\n",
            "Installing collected packages: readability-lxml\n",
            "Successfully installed readability-lxml-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import crochet\n",
        "crochet.setup()\n",
        "\n",
        "import bs4\n",
        "from duckduckgo_search import DDGS\n",
        "from openai import OpenAI\n",
        "import threading\n",
        "import queue\n",
        "from readability import Document\n",
        "import scrapy\n",
        "from scrapy.crawler import CrawlerRunner\n",
        "from scrapy.settings import Settings"
      ],
      "metadata": {
        "id": "fyfWpF06RwZO"
      },
      "id": "fyfWpF06RwZO",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHUNK_SIZE = 13500\n",
        "CHUNK_OVERLAP = 100\n",
        "\n",
        "client = OpenAI()\n",
        "ddgs = DDGS()\n",
        "\n",
        "def extract_useful_information_from_single_chunk(url, title, text, ix, q=None):\n",
        "    '''\n",
        "    This function takes the url, title, and a chunk of text of a webpage, and it asks\n",
        "    openai to extract only the useful information from the text. It returns the result,\n",
        "    which is a string of text, and it also puts the result in a queue if a queue is passed in.\n",
        "    '''\n",
        "    # in this function, we will take the url, title, and some text extracted from the webpage\n",
        "    # by bs4, and we will ask openai to extract only the useful information from the text\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You will be given information about a place. Your task is to extract and summarize the key information. If there is no information, simply return \"No Important Information Found\\n\".\n",
        "    Key information such as the environment and atmosphere of the place. If possible, estimate the range of the cost, and give some recommendations of what food people ordered or activities they did.\n",
        "    Please extract only the useful information from the text. Try not to rewrite the text, but instead extract only the useful information from the text.\n",
        "\n",
        "    Here is a url: {url}\n",
        "    Here is its title: {title}\n",
        "    Here is some text extracted from the webpage:\n",
        "    {text}\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-1106\",\n",
        "        max_tokens=500,\n",
        "        temperature=0.2,\n",
        "        top_p=0.5,\n",
        "        frequency_penalty=0.3,\n",
        "        messages=\n",
        "        [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful assistant to help finding important information.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            },\n",
        "        ],\n",
        "\n",
        "    )\n",
        "    if q:\n",
        "        q.put((ix, response.choices[0].message.content))\n",
        "\n",
        "    text = response.choices[0].message.content.strip()\n",
        "\n",
        "    # sometimes the first line is something like \"Useful information extracted from the text:\", so we remove that\n",
        "    lines = text.splitlines()\n",
        "    if \"useful information\" in lines[0].lower():\n",
        "        text = '\\n'.join(lines[1:])\n",
        "\n",
        "    return (ix, text)\n",
        "\n",
        "def extract_useful_information(url, title, text, max_chunks):\n",
        "    '''\n",
        "    This function takes the url, title, and text of a webpage.\n",
        "    It returns the most useful information from the text.\n",
        "\n",
        "    , and it calls\n",
        "    extract_useful_information_from_single_chunk to extract the useful information.\n",
        "\n",
        "    It does this by breaking the text into chunks, and then calling\n",
        "    extract_useful_information_from_single_chunk on each chunk (which is turn calls openai).\n",
        "    It then concatenates the results from all the chunks.\n",
        "\n",
        "    It uses threading to do this in parallel, because openai is slow.\n",
        "    '''\n",
        "    # Create the chunks with the specified size and overlap\n",
        "    chunks = [text[i:i+CHUNK_SIZE] for i in range(0, len(text), CHUNK_SIZE - CHUNK_OVERLAP)]\n",
        "    chunks = chunks[:max_chunks]\n",
        "\n",
        "    threads = []\n",
        "\n",
        "    q = queue.Queue()\n",
        "\n",
        "    for ix, chunk in enumerate(chunks):\n",
        "        t = threading.Thread(target=extract_useful_information_from_single_chunk, args=(url, title, chunk, ix, q))\n",
        "        threads.append(t)\n",
        "        t.start()\n",
        "\n",
        "    # Wait for all threads to complete\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "\n",
        "    # Get all the results from the queue\n",
        "    results = []\n",
        "    while not q.empty():\n",
        "        results.append(q.get())\n",
        "\n",
        "    # Sort the results by the index\n",
        "    results.sort(key=lambda x: x[0])\n",
        "\n",
        "    # concatenate the text from the results\n",
        "    text = ''.join([x[1] for x in results])\n",
        "\n",
        "    return text\n",
        "\n",
        "def readability(input_text):\n",
        "    '''\n",
        "    This function will use the readability library to extract the useful information from the text.\n",
        "    Document is a class in the readability library. That library is (roughly) a python\n",
        "    port of readability.js, which is a javascript library that is used by firefox to\n",
        "    extract the useful information from a webpage. We will use the Document class to\n",
        "    extract the useful information from the text.\n",
        "    '''\n",
        "\n",
        "    doc = Document(input_text)\n",
        "\n",
        "    summary = doc.summary()\n",
        "\n",
        "    # the summary is html, so we will use bs4 to extract the text\n",
        "    soup = bs4.BeautifulSoup(summary, 'html.parser')\n",
        "    summary_text = soup.get_text()\n",
        "\n",
        "    return summary_text\n",
        "\n",
        "def remove_duplicate_empty_lines(text):\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Replace multiple newlines with a single newline\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "\n",
        "    # Replace multiple tabs with a single tab\n",
        "    text = re.sub(r'\\t+', '\\t', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "class MySpider(scrapy.Spider):\n",
        "    '''\n",
        "    This is the spider that will be used to crawl the webpages. We give this to the scrapy crawler.\n",
        "    '''\n",
        "    name = 'myspider'\n",
        "    start_urls = None\n",
        "    clean_with_llm = False\n",
        "    results = []\n",
        "\n",
        "    def __init__(self, start_urls, clean_with_llm, *args, **kwargs):\n",
        "        super(MySpider, self).__init__(*args, **kwargs)\n",
        "        self.start_urls = start_urls\n",
        "        self.clean_with_llm = clean_with_llm\n",
        "\n",
        "    def start_requests(self):\n",
        "        for url in self.start_urls:\n",
        "            yield scrapy.Request(url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        body_html = response.body.decode('utf-8')\n",
        "\n",
        "        url = response.url\n",
        "\n",
        "        soup = bs4.BeautifulSoup(body_html, 'html.parser')\n",
        "        # Check if title tag exists\n",
        "        if soup.title:\n",
        "            title = soup.title.string\n",
        "        else:\n",
        "            title = \"No Title Found\"\n",
        "        text = soup.get_text()\n",
        "        text = remove_duplicate_empty_lines(text)\n",
        "\n",
        "        if self.clean_with_llm:\n",
        "            useful_text = extract_useful_information(url, title, text, 50)\n",
        "        else:\n",
        "            useful_text = readability(body_html)\n",
        "        useful_text = remove_duplicate_empty_lines(useful_text)\n",
        "\n",
        "        self.results.append({\n",
        "            'url': url,\n",
        "            'title': title,\n",
        "            # 'text': text,\n",
        "            'text': '',\n",
        "            'useful_text': useful_text\n",
        "        })\n",
        "\n",
        "\n",
        "\n",
        "@crochet.run_in_reactor\n",
        "def run_spider(url_list, clean_with_llm):\n",
        "    # Define custom settings\n",
        "    custom_settings = {\n",
        "        'LOG_ENABLED': False,  # disable logging.\n",
        "        'RANDOMIZE_DOWNLOAD_DELAY': True, # random .5 - 1.5 seconds\n",
        "    }\n",
        "\n",
        "    # Create a settings object\n",
        "    settings = Settings()\n",
        "    settings.setdict(custom_settings)\n",
        "\n",
        "    # Create a CrawlerRunner with the custom settings\n",
        "    crawler = CrawlerRunner(settings)\n",
        "    deferred = crawler.crawl(MySpider, start_urls=url_list, clean_with_llm=clean_with_llm)\n",
        "    return deferred\n",
        "\n",
        "def ddgsearch(query, numresults=10, clean_with_llm=False):\n",
        "    '''\n",
        "    This function performs a search on duckduckgo and returns the results.\n",
        "    It uses the scrapy library to download the pages and extract the useful information.\n",
        "    It extracts useful information from the pages using either the readability library\n",
        "    or openai, depending on the value of clean_with_llm.\n",
        "\n",
        "    query: the query to search for\n",
        "    numresults: the number of results to return\n",
        "    clean_with_llm: if True, use openai to clean the text. If False, use readability.\n",
        "    '''\n",
        "\n",
        "    # perform the search\n",
        "    results = list(ddgs.text(query, max_results=numresults))\n",
        "\n",
        "    # get the urls\n",
        "    urls = [result['href'] for result in results]\n",
        "    urls = urls[:numresults]\n",
        "\n",
        "    print(urls)\n",
        "    MySpider.results = []\n",
        "    eventual_result = run_spider(urls, clean_with_llm)\n",
        "\n",
        "    # Wait for the specified time or until the result is ready\n",
        "    try:\n",
        "        results = eventual_result.wait(timeout=20.0)\n",
        "    except crochet.TimeoutError:\n",
        "        raise Exception(\"The scraping operation timed out.\")\n",
        "\n",
        "    return MySpider.results"
      ],
      "metadata": {
        "id": "LfMjy_NLRwuY"
      },
      "id": "LfMjy_NLRwuY",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = ddgsearch(\"R. Thomas Deluxe Grill\", numresults=5, clean_with_llm=True)\n",
        "len(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzBXg6BCUhAj",
        "outputId": "764315ae-809f-4f0c-868e-058be9de9b68"
      },
      "id": "UzBXg6BCUhAj",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:twisted:/usr/local/lib/python3.10/dist-packages/scrapy/utils/request.py:254: scrapy.exceptions.ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
            "\n",
            "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
            "\n",
            "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.rthomasdeluxegrill.net/', 'https://www.yelp.com/biz/r-thomas-deluxe-grill-atlanta', 'https://rthomasdeluxegrill.business.site/', 'https://www.facebook.com/rthomasdeluxegrill/', 'https://www.tripadvisor.com/Restaurant_Review-g60898-d435430-Reviews-R_Thomas_Deluxe_Grill-Atlanta_Georgia.html']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for result in results:\n",
        "    print(result['useful_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roau5jzoUyPc",
        "outputId": "f9313e36-8357-4711-bc5b-69349b550363"
      },
      "id": "roau5jzoUyPc",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The R. Thomas Deluxe Grill is an American restaurant in Atlanta with a unique and fun atmosphere. The service is highly praised, and the food is described as amazing and delicious. The cost is mentioned as reasonably priced. Recommendations for food include the spicy fish tacos, \"The Champ\" fresh made juice, and the big breakfast special with French toast and strawberries. The restaurant is open until 5:00 AM on certain days.\n",
            "I'm sorry, but I am unable to access external websites or URLs. Therefore, I cannot extract information from the provided URL. If you have specific information or details you'd like me to help with, please feel free to share them here.\n",
            "The R. Thomas Deluxe Grill in Atlanta, Georgia is a vegetarian and vegan-friendly restaurant that offers a diverse menu including breakfast, burgers, wings, and fresh pressed juice. The atmosphere is described as laid back with vibrant and whimsical decor, including caged parrots outside. The restaurant is open from 7:00 AM to 11:00 PM, with extended hours until 5:00 AM on weekends. Customers recommend trying the French toast, Thai Express, Spicy Fish Tacos, and the Mojo Jojo smoothie. The cost is estimated to be in the range of $$ (moderate). Overall, it is known for its eclectic atmosphere and diverse menu options.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# queries =[\n",
        "#     'Rodney Cook Sr. Park',\n",
        "#     'Atlanta Street Art Tours',\n",
        "#     'SCAD Art Sales',\n",
        "#     'R. Thomas Deluxe Grill',\n",
        "#     'Caribbean Delight',\n",
        "#     'Tech Square',\n",
        "#     'Peachtree Battle Shopping Center',\n",
        "#     'Flats at Ponce City Market',\n",
        "# ]\n",
        "\n",
        "# for query in queries:\n",
        "#     results = ddgsearch(query, numresults=5, clean_with_llm=True)\n",
        "#     for result in results:\n",
        "#         print(result['useful_text'])"
      ],
      "metadata": {
        "id": "YNuXQaDBiLvN"
      },
      "id": "YNuXQaDBiLvN",
      "execution_count": 27,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "langchain"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "578e1e8dce4dc6c542f1ea2d66a2d9db6ef592936dcc314004bdae386f827d38"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}